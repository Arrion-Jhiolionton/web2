{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFqw98F1StIualJNtpNKSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d3c2e46ba7d469f928a90b021bea362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b86fc569f24481380e22fb1115f813f",
              "IPY_MODEL_4c95e7e4966a4993b75fa54999360fe0",
              "IPY_MODEL_aa8e6c0f2a1b460f97b59d9c00224225"
            ],
            "layout": "IPY_MODEL_5f4d75c4e68d4f118c79ba9212cb721c"
          }
        },
        "2b86fc569f24481380e22fb1115f813f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4078a476fea8441cbb7e83a616f0e682",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_163d432d6509491b8c7831545e44d335",
            "value": "Processing:‚Äá100%"
          }
        },
        "4c95e7e4966a4993b75fa54999360fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac20163d7a5640ff848567f3a9028984",
            "max": 302,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dae440e57b54916b92a66b6f1a08723",
            "value": 302
          }
        },
        "aa8e6c0f2a1b460f97b59d9c00224225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f51cad56e874ac8923c449afcb4ca15",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f9b9e07f6c5d41c3a30266fdbf36b63c",
            "value": "‚Äá302/302‚Äá[00:35&lt;00:00,‚Äá16.04it/s]"
          }
        },
        "5f4d75c4e68d4f118c79ba9212cb721c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4078a476fea8441cbb7e83a616f0e682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163d432d6509491b8c7831545e44d335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac20163d7a5640ff848567f3a9028984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dae440e57b54916b92a66b6f1a08723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f51cad56e874ac8923c449afcb4ca15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b9e07f6c5d41c3a30266fdbf36b63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arrion-Jhiolionton/web2/blob/main/augement302.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload Image ZIP file\n",
        "print(\"üì§ Please upload your IMAGE ZIP file...\")\n",
        "uploaded_zip = files.upload()\n",
        "zip_filename = list(uploaded_zip.keys())[0]\n",
        "print(f\"‚úÖ Uploaded ZIP: {zip_filename}\")\n",
        "\n",
        "# Extract images\n",
        "print(f\"üì¶ Extracting {zip_filename}...\")\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset/images')\n",
        "print(\"‚úÖ Images extracted!\")\n",
        "\n",
        "# Upload JSON file\n",
        "print(\"\\nüì§ Please upload your JSON annotation file...\")\n",
        "uploaded_json = files.upload()\n",
        "json_filename = list(uploaded_json.keys())[0]\n",
        "print(f\"‚úÖ Uploaded JSON: {json_filename}\")\n",
        "\n",
        "# Move JSON to dataset folder\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "os.rename(json_filename, f'dataset/{json_filename}')\n",
        "print(f\"‚úÖ JSON moved to dataset/{json_filename}\")\n",
        "\n",
        "# Show contents\n",
        "print(\"\\nüìÅ Dataset structure:\")\n",
        "print(f\"Images: {len(os.listdir('dataset/images'))} files\")\n",
        "print(f\"JSON: dataset/{json_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "5nTn2BJYraPo",
        "outputId": "09f14540-7a71-4e12-e1ae-f16858b7e9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì§ Please upload your IMAGE ZIP file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-611c6310-3335-4149-9d20-6f7b05dc2f22\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-611c6310-3335-4149-9d20-6f7b05dc2f22\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving images.zip to images (1).zip\n",
            "‚úÖ Uploaded ZIP: images (1).zip\n",
            "üì¶ Extracting images (1).zip...\n",
            "‚úÖ Images extracted!\n",
            "\n",
            "üì§ Please upload your JSON annotation file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b601726-acda-41bc-8b20-e9bddd3d1e04\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b601726-acda-41bc-8b20-e9bddd3d1e04\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving prescription_labeling.json to prescription_labeling.json\n",
            "‚úÖ Uploaded JSON: prescription_labeling.json\n",
            "‚úÖ JSON moved to dataset/prescription_labeling.json\n",
            "\n",
            "üìÅ Dataset structure:\n",
            "Images: 1 files\n",
            "JSON: dataset/prescription_labeling.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install albumentations\n",
        "!pip install -q --upgrade albumentations opencv-python\n",
        "\n",
        "print(\"‚úÖ All libraries installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O_bVFxxs5rV",
        "outputId": "9a4908ac-3b13-4f3b-d704-cfd294e476d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Check dataset structure\n",
        "dataset_path = Path('dataset')\n",
        "\n",
        "# Find JSON file\n",
        "json_files = list(dataset_path.glob('*.json'))\n",
        "print(f\"üìÑ JSON files found: {len(json_files)}\")\n",
        "for jf in json_files:\n",
        "    print(f\"  - {jf.name}\")\n",
        "\n",
        "# Find images\n",
        "images_base_path = dataset_path / 'images'\n",
        "# Check if there's a single subdirectory and adjust images_path\n",
        "if images_base_path.exists() and len(os.listdir(images_base_path)) == 1:\n",
        "    first_item = os.listdir(images_base_path)[0]\n",
        "    if (images_base_path / first_item).is_dir():\n",
        "        images_path = images_base_path / first_item\n",
        "        print(f\"\\nDetected subdirectory: {images_path}. Searching for images there.\")\n",
        "    else:\n",
        "        images_path = images_base_path\n",
        "        print(f\"\\nNo subdirectory detected. Searching for images in: {images_path}.\")\n",
        "else:\n",
        "    images_path = images_base_path\n",
        "    print(f\"\\nSearching for images in: {images_path}.\")\n",
        "\n",
        "# Add debugging to see what's actually in the directory where images are expected\n",
        "print(f\"\\nüîé Contents of {images_path}:\")\n",
        "if images_path.exists():\n",
        "    for item in os.listdir(images_path):\n",
        "        print(f\"  - {item}\")\n",
        "else:\n",
        "    print(f\"  - Directory {images_path} does not exist.\")\n",
        "\n",
        "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "images = []\n",
        "for ext in image_extensions:\n",
        "    images.extend(list(images_path.glob(ext)))\n",
        "\n",
        "print(f\"\\nüñºÔ∏è  Images found: {len(images)}\")\n",
        "\n",
        "# Load JSON to check\n",
        "if json_files:\n",
        "    with open(json_files[0], 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    print(f\"\\n‚úÖ JSON contains {len(data)} tasks\")\n",
        "else:\n",
        "    print(\"‚ùå No JSON file found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NztVRRnVtAl7",
        "outputId": "82b95161-6972-4f8a-b02c-87be9f0b8a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ JSON files found: 1\n",
            "  - prescription_labeling.json\n",
            "\n",
            "Detected subdirectory: dataset/images/Merge 300. Searching for images there.\n",
            "\n",
            "üîé Contents of dataset/images/Merge 300:\n",
            "  - img_0519.jpg\n",
            "  - img_1008.jpg\n",
            "  - img_0608.jpg\n",
            "  - img_1051.jpg\n",
            "  - img_0964.jpg\n",
            "  - img_0072.jpg\n",
            "  - img_0085.jpg\n",
            "  - img_1066.jpg\n",
            "  - img_0604.jpg\n",
            "  - img_1075.jpg\n",
            "  - img_0083.jpg\n",
            "  - img_1027.jpg\n",
            "  - img_1028.jpg\n",
            "  - img_0579.jpg\n",
            "  - img_0999.jpg\n",
            "  - img_0097.jpg\n",
            "  - img_0514.jpg\n",
            "  - img_1093.jpg\n",
            "  - img_1069.jpg\n",
            "  - img_0589.jpg\n",
            "  - img_0972.jpg\n",
            "  - img_0071.jpg\n",
            "  - img_0008.jpg\n",
            "  - img_0010.jpg\n",
            "  - img_0092.jpg\n",
            "  - img_0657.jpg\n",
            "  - img_1019.jpg\n",
            "  - img_0015.jpg\n",
            "  - img_1005.jpg\n",
            "  - img_0693.jpg\n",
            "  - img_0591.jpg\n",
            "  - img_0037.jpg\n",
            "  - img_1021.jpg\n",
            "  - img_1002.jpg\n",
            "  - img_0994.jpg\n",
            "  - img_0045.jpg\n",
            "  - img_0991.jpg\n",
            "  - img_1025.jpg\n",
            "  - img_0058.jpg\n",
            "  - img_0495.jpg\n",
            "  - img_0528.jpg\n",
            "  - img_1086.jpg\n",
            "  - img_0491.jpg\n",
            "  - img_0587.jpg\n",
            "  - img_1046.jpg\n",
            "  - img_1108.jpg\n",
            "  - img_0526.jpg\n",
            "  - img_0021.jpg\n",
            "  - img_1103.jpg\n",
            "  - img_1048.jpg\n",
            "  - img_0683.jpg\n",
            "  - img_0691.jpg\n",
            "  - img_1012.jpg\n",
            "  - img_0622.jpg\n",
            "  - img_1044.jpg\n",
            "  - img_0094.jpg\n",
            "  - img_0577.jpg\n",
            "  - img_0596.jpg\n",
            "  - img_0029.jpg\n",
            "  - img_0080.jpg\n",
            "  - img_1013.jpg\n",
            "  - img_0618.jpg\n",
            "  - img_0969.jpg\n",
            "  - img_0049.jpg\n",
            "  - img_1055.jpg\n",
            "  - img_0623.jpg\n",
            "  - img_0696.jpg\n",
            "  - img_0502.jpg\n",
            "  - img_0981.jpg\n",
            "  - img_0056.jpg\n",
            "  - img_0975.jpg\n",
            "  - img_0088.jpg\n",
            "  - img_0497.jpg\n",
            "  - img_1065.jpg\n",
            "  - img_0003.jpg\n",
            "  - img_0627.jpg\n",
            "  - img_0031.jpg\n",
            "  - img_1040.jpg\n",
            "  - img_0096.jpg\n",
            "  - img_0494.jpg\n",
            "  - img_0594.jpg\n",
            "  - img_0500.jpg\n",
            "  - img_0987.jpg\n",
            "  - img_0013.jpg\n",
            "  - img_0658.jpg\n",
            "  - img_0078.jpg\n",
            "  - img_0640.jpg\n",
            "  - img_0968.jpg\n",
            "  - img_0955.jpg\n",
            "  - img_1062.jpg\n",
            "  - img_0985.jpg\n",
            "  - img_0016.jpg\n",
            "  - img_0956.jpg\n",
            "  - img_1068.jpg\n",
            "  - img_0073.jpg\n",
            "  - img_1030.jpg\n",
            "  - img_0017.jpg\n",
            "  - img_1053.jpg\n",
            "  - img_0982.jpg\n",
            "  - img_1059.jpg\n",
            "  - img_1071.jpg\n",
            "  - img_0992.jpg\n",
            "  - img_0529.jpg\n",
            "  - img_0967.jpg\n",
            "  - img_0971.jpg\n",
            "  - img_0101.jpg\n",
            "  - img_1058.jpg\n",
            "  - img_0009.jpg\n",
            "  - img_0051.jpg\n",
            "  - img_0492.jpg\n",
            "  - img_0501.jpg\n",
            "  - img_0635.jpg\n",
            "  - img_0060.jpg\n",
            "  - img_0995.jpg\n",
            "  - img_1035.jpg\n",
            "  - img_0509.jpg\n",
            "  - img_0988.jpg\n",
            "  - img_0986.jpg\n",
            "  - img_0091.jpg\n",
            "  - img_0617.jpg\n",
            "  - img_0980.jpg\n",
            "  - img_0578.jpg\n",
            "  - img_0079.jpg\n",
            "  - img_0057.jpg\n",
            "  - img_1010.jpg\n",
            "  - img_0965.jpg\n",
            "  - img_1020.jpg\n",
            "  - img_0958.jpg\n",
            "  - img_0585.jpg\n",
            "  - img_0510.jpg\n",
            "  - img_0506.jpg\n",
            "  - img_0970.jpg\n",
            "  - img_0631.jpg\n",
            "  - img_1032.jpg\n",
            "  - img_0082.jpg\n",
            "  - img_0496.jpg\n",
            "  - img_1043.jpg\n",
            "  - img_0067.jpg\n",
            "  - img_0050.jpg\n",
            "  - img_0047.jpg\n",
            "  - img_0002.jpg\n",
            "  - img_1009.jpg\n",
            "  - img_0061.jpg\n",
            "  - img_0053.jpg\n",
            "  - img_0077.jpg\n",
            "  - img_0025.jpg\n",
            "  - img_1045.jpg\n",
            "  - img_1023.jpg\n",
            "  - img_0996.jpg\n",
            "  - img_1064.jpg\n",
            "  - img_0046.jpg\n",
            "  - img_0005.jpg\n",
            "  - img_0100.jpg\n",
            "  - img_0054.jpg\n",
            "  - img_0572.jpg\n",
            "  - img_0084.jpg\n",
            "  - img_1022.jpg\n",
            "  - img_0020.jpg\n",
            "  - img_1011.jpg\n",
            "  - img_0035.jpg\n",
            "  - img_1037.jpg\n",
            "  - img_1016.jpg\n",
            "  - img_0977.jpg\n",
            "  - img_1041.jpg\n",
            "  - img_0505.jpg\n",
            "  - img_0990.jpg\n",
            "  - img_0065.jpg\n",
            "  - img_0036.jpg\n",
            "  - img_0978.jpg\n",
            "  - img_0597.jpg\n",
            "  - img_0660.jpg\n",
            "  - img_0059.jpg\n",
            "  - img_1026.jpg\n",
            "  - img_1001.jpg\n",
            "  - img_0089.jpg\n",
            "  - img_1050.jpg\n",
            "  - img_0637.jpg\n",
            "  - img_0068.jpg\n",
            "  - img_0081.jpg\n",
            "  - img_1063.jpg\n",
            "  - img_0004.jpg\n",
            "  - img_0516.jpg\n",
            "  - img_0039.jpg\n",
            "  - img_0042.jpg\n",
            "  - img_0602.jpg\n",
            "  - img_0582.jpg\n",
            "  - img_1067.jpg\n",
            "  - img_0076.jpg\n",
            "  - img_0997.jpg\n",
            "  - img_0062.jpg\n",
            "  - img_0628.jpg\n",
            "  - img_0095.jpg\n",
            "  - img_1000.jpg\n",
            "  - img_1061.jpg\n",
            "  - img_1024.jpg\n",
            "  - img_0070.jpg\n",
            "  - img_0973.jpg\n",
            "  - img_1015.jpg\n",
            "  - img_1006.jpg\n",
            "  - img_0508.jpg\n",
            "  - img_0074.jpg\n",
            "  - img_1007.jpg\n",
            "  - img_0645.jpg\n",
            "  - img_1054.jpg\n",
            "  - img_0011.jpg\n",
            "  - img_1031.jpg\n",
            "  - img_0960.jpg\n",
            "  - img_0086.jpg\n",
            "  - img_1038.jpg\n",
            "  - img_0613.jpg\n",
            "  - img_0603.jpg\n",
            "  - img_0090.jpg\n",
            "  - img_1056.jpg\n",
            "  - img_0075.jpg\n",
            "  - img_0524.jpg\n",
            "  - img_1049.jpg\n",
            "  - img_0006.jpg\n",
            "  - img_0023.jpg\n",
            "  - img_0069.jpg\n",
            "  - img_0584.jpg\n",
            "  - img_0030.jpg\n",
            "  - img_0099.jpg\n",
            "  - img_0087.jpg\n",
            "  - img_0993.jpg\n",
            "  - img_0518.jpg\n",
            "  - img_1029.jpg\n",
            "  - img_0066.jpg\n",
            "  - img_1052.jpg\n",
            "  - img_0493.jpg\n",
            "  - img_1039.jpg\n",
            "  - img_0055.jpg\n",
            "  - img_0052.jpg\n",
            "  - img_1018.jpg\n",
            "  - img_0512.jpg\n",
            "  - img_0515.jpg\n",
            "  - img_0012.jpg\n",
            "  - img_0007.jpg\n",
            "  - img_1085.jpg\n",
            "  - img_0093.jpg\n",
            "  - img_0504.jpg\n",
            "  - img_0521.jpg\n",
            "  - img_1070.jpg\n",
            "  - img_0063.jpg\n",
            "  - img_0507.jpg\n",
            "  - img_0064.jpg\n",
            "  - img_0523.jpg\n",
            "  - img_0560.jpg\n",
            "  - img_0525.jpg\n",
            "  - img_0615.jpg\n",
            "  - img_0027.jpg\n",
            "  - img_0511.jpg\n",
            "  - img_0621.jpg\n",
            "  - img_0626.jpg\n",
            "  - img_1060.jpg\n",
            "  - img_0032.jpg\n",
            "  - img_0966.jpg\n",
            "  - img_0983.jpg\n",
            "  - img_1047.jpg\n",
            "  - img_0647.jpg\n",
            "  - img_1089.jpg\n",
            "  - img_0998.jpg\n",
            "  - img_0022.jpg\n",
            "  - img_0038.jpg\n",
            "  - img_0098.jpg\n",
            "  - img_0028.jpg\n",
            "  - img_0024.jpg\n",
            "  - img_0041.jpg\n",
            "  - img_1014.jpg\n",
            "  - img_1017.jpg\n",
            "  - img_0033.jpg\n",
            "  - img_0026.jpg\n",
            "  - img_0018.jpg\n",
            "  - img_1072.jpg\n",
            "  - img_1042.jpg\n",
            "  - img_0984.jpg\n",
            "  - img_0989.jpg\n",
            "  - img_1073.jpg\n",
            "  - img_1036.jpg\n",
            "  - img_0040.jpg\n",
            "  - img_1033.jpg\n",
            "  - img_1057.jpg\n",
            "  - img_0043.jpg\n",
            "  - img_0979.jpg\n",
            "  - img_0586.jpg\n",
            "  - img_0499.jpg\n",
            "  - img_0034.jpg\n",
            "  - img_0963.jpg\n",
            "  - img_1003.jpg\n",
            "  - img_0044.jpg\n",
            "  - img_0598.jpg\n",
            "  - img_0048.jpg\n",
            "  - img_1034.jpg\n",
            "  - img_0498.jpg\n",
            "  - img_0019.jpg\n",
            "  - img_1004.jpg\n",
            "  - img_0527.jpg\n",
            "  - img_0537.jpg\n",
            "  - img_0001.jpg\n",
            "  - img_0599.jpg\n",
            "  - img_0014.jpg\n",
            "  - img_0954.jpg\n",
            "  - img_1080.jpg\n",
            "\n",
            "üñºÔ∏è  Images found: 302\n",
            "\n",
            "‚úÖ JSON contains 302 tasks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import albumentations as A\n",
        "from albumentations.core.bbox_utils import BboxParams\n",
        "import copy\n",
        "from tqdm.notebook import tqdm  # Progress bar\n",
        "\n",
        "# ==================== AUGMENTATION CONFIGS ====================\n",
        "def get_5_augmentation_configs():\n",
        "    \"\"\"5‡¶ü‡¶æ augmentation configurations\"\"\"\n",
        "\n",
        "    bbox_params = BboxParams(\n",
        "        format='albumentations',\n",
        "        label_fields=['class_labels'],\n",
        "        min_visibility=0.3\n",
        "    )\n",
        "\n",
        "    configs = [\n",
        "        # Config 1: Brightness & Contrast\n",
        "        A.Compose([\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.9),\n",
        "        ], bbox_params=bbox_params),\n",
        "\n",
        "        # Config 2: Rotation & Scale (reduced limits)\n",
        "        A.Compose([\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.08, scale_limit=0.10, rotate_limit=5, # Adjusted scale and rotate limits\n",
        "                border_mode=cv2.BORDER_CONSTANT, value=255, p=0.9\n",
        "            ),\n",
        "        ], bbox_params=bbox_params),\n",
        "\n",
        "        # Config 3: Blur\n",
        "        A.Compose([\n",
        "            A.OneOf([\n",
        "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
        "                A.MotionBlur(blur_limit=5, p=1.0),\n",
        "            ], p=0.9),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "        ], bbox_params=bbox_params),\n",
        "\n",
        "        # Config 4: Noise & Compression\n",
        "        A.Compose([\n",
        "            A.GaussNoise(var_limit=(15, 40), p=0.7),\n",
        "            A.ImageCompression(quality_lower=75, quality_upper=95, p=0.7),\n",
        "        ], bbox_params=bbox_params),\n",
        "\n",
        "        # Config 5: Combined (reduced limits)\n",
        "        A.Compose([\n",
        "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.08, rotate_limit=3, p=0.7), # Adjusted scale and rotate limits\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.6),\n",
        "            A.OneOf([\n",
        "                A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
        "                A.GaussNoise(var_limit=(10, 25), p=1.0),\n",
        "            ], p=0.5),\n",
        "            A.ImageCompression(quality_lower=80, quality_upper=100, p=0.4),\n",
        "        ], bbox_params=bbox_params),\n",
        "    ]\n",
        "\n",
        "    return configs\n",
        "\n",
        "# ==================== EXTRACT BOXES ====================\n",
        "def extract_boxes_from_labelstudio_full(task_item):\n",
        "    \"\"\"Label Studio full export format ‡¶•‡ßá‡¶ï‡ßá boxes extract ‡¶ï‡¶∞‡ßã\"\"\"\n",
        "    boxes = []\n",
        "    class_labels = []\n",
        "    transcriptions = []\n",
        "\n",
        "    if 'annotations' not in task_item or len(task_item['annotations']) == 0:\n",
        "        return None\n",
        "\n",
        "    annotation = task_item['annotations'][0]\n",
        "    results = annotation['result']\n",
        "\n",
        "    for result in results:\n",
        "        if result['type'] == 'rectanglelabels':\n",
        "            x = result['value']['x'] / 100.0\n",
        "            y = result['value']['y'] / 100.0\n",
        "            w = result['value']['width'] / 100.0\n",
        "            h = result['value']['height'] / 100.0\n",
        "\n",
        "            # Clip original bounding box coordinates to [0, 1]\n",
        "            x_min = np.clip(x, 0.0, 1.0)\n",
        "            y_min = np.clip(y, 0.0, 1.0)\n",
        "            x_max = np.clip(x + w, 0.0, 1.0)\n",
        "            y_max = np.clip(y + h, 0.0, 1.0)\n",
        "\n",
        "            # Ensure width/height are still positive after clipping\n",
        "            clipped_w = x_max - x_min\n",
        "            clipped_h = y_max - y_min\n",
        "\n",
        "            if clipped_w > 0 and clipped_h > 0:\n",
        "                boxes.append([x_min, y_min, x_max, y_max])\n",
        "                class_labels.append(result['value']['rectanglelabels'][0])\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  Dropped a bounding box due to excessive clipping in image: {task_item['data']['image']} - {result['value']}\")\n",
        "\n",
        "        elif result['type'] == 'textarea':\n",
        "            text_content = result['value']['text'][0] if result['value']['text'] else \"\"\n",
        "            transcriptions.append(text_content)\n",
        "\n",
        "    return {\n",
        "        'boxes': boxes,\n",
        "        'class_labels': class_labels,\n",
        "        'transcriptions': transcriptions\n",
        "    }\n",
        "\n",
        "# ==================== AUGMENT IMAGE ====================\n",
        "def augment_image_with_configs(image_path, annotation_data, configs):\n",
        "    \"\"\"5‡¶ü‡¶æ config apply ‡¶ï‡¶∞‡ßã\"\"\"\n",
        "\n",
        "    image = cv2.imread(str(image_path))\n",
        "    if image is None:\n",
        "        print(f\"‚ö†Ô∏è  Could not read image: {image_path}\")\n",
        "        return []\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    augmented_samples = []\n",
        "\n",
        "    for idx, transform in enumerate(configs):\n",
        "        try:\n",
        "            transformed = transform(\n",
        "                image=image,\n",
        "                bboxes=annotation_data['boxes'],\n",
        "                class_labels=annotation_data['class_labels']\n",
        "            )\n",
        "\n",
        "            # Removed manual clipping here as it was ineffective against internal Albumentations validation\n",
        "            # Albumentations will now handle clipping/dropping based on its internal logic and min_visibility\n",
        "\n",
        "            augmented_samples.append({\n",
        "                'image': transformed['image'],\n",
        "                'boxes': transformed['bboxes'],\n",
        "                'class_labels': transformed['class_labels'],\n",
        "                'transcriptions': annotation_data['transcriptions'],\n",
        "                'image_shape': (height, width),\n",
        "                'config_id': idx\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Augmentation failed for image {image_path.name} with config {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return augmented_samples\n",
        "\n",
        "# ==================== CREATE AUGMENTED ANNOTATION ====================\n",
        "def create_augmented_task(original_task, augmented_data, aug_index, image_name):\n",
        "    \"\"\"Augmented image ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø Label Studio task ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßã\"\"\"\n",
        "\n",
        "    new_task = copy.deepcopy(original_task)\n",
        "\n",
        "    aug_image_name = f\"aug{aug_index}_{image_name}\"\n",
        "    new_task['data']['image'] = f\"/data/upload/augmented/{aug_image_name}\"\n",
        "    new_task['id'] = f\"{original_task['id']}_aug{aug_index}\"\n",
        "    new_task['predictions'] = []\n",
        "\n",
        "    new_results = []\n",
        "    orig_height, orig_width = augmented_data['image_shape']\n",
        "\n",
        "    for i, (box, label) in enumerate(zip(augmented_data['boxes'], augmented_data['class_labels'])):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "\n",
        "        x = x_min * 100\n",
        "        y = y_min * 100\n",
        "        width = (x_max - x_min) * 100\n",
        "        height = (y_max - y_min) * 100\n",
        "\n",
        "        # Rectangle label\n",
        "        new_results.append({\n",
        "            \"original_width\": orig_width,\n",
        "            \"original_height\": orig_height,\n",
        "            \"image_rotation\": 0,\n",
        "            \"value\": {\n",
        "                \"x\": x,\n",
        "                \"y\": y,\n",
        "                \"width\": width,\n",
        "                \"height\": height,\n",
        "                \"rotation\": 0,\n",
        "                \"rectanglelabels\": [label]\n",
        "            },\n",
        "            \"id\": f\"aug{aug_index}_box{i}\",\n",
        "            \"from_name\": \"ner_labels\",\n",
        "            \"to_name\": \"image\",\n",
        "            \"type\": \"rectanglelabels\",\n",
        "            \"origin\": \"augmentation\"\n",
        "        })\n",
        "\n",
        "        # Transcription\n",
        "        transcription = augmented_data['transcriptions'][i] if i < len(augmented_data['transcriptions']) else \"\"\n",
        "        new_results.append({\n",
        "            \"original_width\": orig_width,\n",
        "            \"original_height\": orig_height,\n",
        "            \"image_rotation\": 0,\n",
        "            \"value\": {\n",
        "                \"x\": x,\n",
        "                \"y\": y,\n",
        "                \"width\": width,\n",
        "                \"height\": height,\n",
        "                \"rotation\": 0,\n",
        "                \"text\": [transcription]\n",
        "            },\n",
        "            \"id\": f\"aug{aug_index}_text{i}\",\n",
        "            \"from_name\": \"transcription\",\n",
        "            \"to_name\": \"image\",\n",
        "            \"type\": \"textarea\",\n",
        "            \"origin\": \"augmentation\"\n",
        "        })\n",
        "\n",
        "    new_task['annotations'][0]['result'] = new_results\n",
        "    new_task['annotations'][0]['result_count'] = len(new_results)\n",
        "\n",
        "    return new_task\n",
        "\n",
        "print(\"‚úÖ All functions loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqJ6TQAstSmL",
        "outputId": "0cd28221-5696-42c1-eb5f-33059b4820ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All functions loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_dataset_colab(json_path, images_dir, output_dir):\n",
        "    \"\"\"Complete augmentation pipeline for Colab\"\"\"\n",
        "\n",
        "    output_dir = Path(output_dir)\n",
        "    aug_images_dir = output_dir / 'augmented_images'\n",
        "    aug_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load annotations\n",
        "    print(\"üìÇ Loading annotations...\")\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        tasks = json.load(f)\n",
        "    print(f\"‚úÖ Loaded {len(tasks)} tasks\\n\")\n",
        "\n",
        "    # Get configs\n",
        "    configs = get_5_augmentation_configs()\n",
        "    print(f\"üé® Using {len(configs)} augmentation configs\\n\")\n",
        "\n",
        "    # Process each task with progress bar\n",
        "    all_augmented_tasks = []\n",
        "    stats = {'original': len(tasks), 'augmented': 0, 'failed': 0, 'skipped': 0}\n",
        "\n",
        "    for task in tqdm(tasks, desc=\"Processing\"):\n",
        "        image_path_str = task['data']['image']\n",
        "        image_name = image_path_str.split('/')[-1]\n",
        "\n",
        "        # Find image in dataset/images directory\n",
        "        image_path = Path(images_dir) / image_name\n",
        "\n",
        "        if not image_path.exists():\n",
        "            stats['failed'] += 1\n",
        "            continue\n",
        "\n",
        "        # Extract boxes\n",
        "        annotation_data = extract_boxes_from_labelstudio_full(task)\n",
        "\n",
        "        if annotation_data is None or len(annotation_data['boxes']) == 0:\n",
        "            stats['skipped'] += 1\n",
        "            continue\n",
        "\n",
        "        # Augment\n",
        "        augmented_samples = augment_image_with_configs(\n",
        "            image_path,\n",
        "            annotation_data,\n",
        "            configs\n",
        "        )\n",
        "\n",
        "        # Save augmented images and tasks\n",
        "        for aug_idx, aug_sample in enumerate(augmented_samples):\n",
        "            aug_image_name = f\"aug{aug_idx}_{image_name}\"\n",
        "            aug_image_path = aug_images_dir / aug_image_name\n",
        "\n",
        "            aug_image_bgr = cv2.cvtColor(aug_sample['image'], cv2.COLOR_RGB2BGR)\n",
        "            cv2.imwrite(str(aug_image_path), aug_image_bgr)\n",
        "\n",
        "            aug_task = create_augmented_task(task, aug_sample, aug_idx, image_name)\n",
        "            all_augmented_tasks.append(aug_task)\n",
        "            stats['augmented'] += 1\n",
        "\n",
        "    # Combine and save\n",
        "    final_tasks = tasks + all_augmented_tasks\n",
        "\n",
        "    output_json = output_dir / 'augmented_annotations.json'\n",
        "    with open(output_json, 'w', encoding='utf-8') as f:\n",
        "        json.dump(final_tasks, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä AUGMENTATION COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Original tasks:       {stats['original']}\")\n",
        "    print(f\"Augmented tasks:      {stats['augmented']}\")\n",
        "    print(f\"Failed:               {stats['failed']}\")\n",
        "    print(f\"Skipped (no boxes):   {stats['skipped']}\")\n",
        "    print(f\"Total dataset:        {len(final_tasks)}\")\n",
        "    print(f\"Augmentation factor:  {stats['augmented']/max(stats['original']-stats['skipped'],1):.1f}x\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"‚úÖ JSON: {output_json}\")\n",
        "    print(f\"‚úÖ Images: {aug_images_dir}/\")\n",
        "\n",
        "    return final_tasks, stats\n",
        "\n",
        "# Find JSON and images automatically\n",
        "dataset_path = Path('dataset')\n",
        "json_files = list(dataset_path.glob('*.json'))\n",
        "\n",
        "if json_files:\n",
        "    JSON_PATH = json_files[0]\n",
        "\n",
        "    # Determine IMAGES_DIR correctly, accounting for potential subdirectories\n",
        "    images_base_path = dataset_path / 'images'\n",
        "    if images_base_path.exists() and len(os.listdir(images_base_path)) == 1:\n",
        "        first_item = os.listdir(images_base_path)[0]\n",
        "        if (images_base_path / first_item).is_dir():\n",
        "            IMAGES_DIR = images_base_path / first_item\n",
        "        else:\n",
        "            IMAGES_DIR = images_base_path\n",
        "    else:\n",
        "        IMAGES_DIR = images_base_path\n",
        "\n",
        "    OUTPUT_DIR = 'augmented_output'\n",
        "\n",
        "    print(f\"üìÑ Using JSON: {JSON_PATH}\")\n",
        "    print(f\"üñºÔ∏è  Images from: {IMAGES_DIR}\\n\")\n",
        "\n",
        "    # RUN AUGMENTATION\n",
        "    final_data, stats = augment_dataset_colab(JSON_PATH, IMAGES_DIR, OUTPUT_DIR)\n",
        "\n",
        "    print(\"\\nüéâ ALL DONE!\")\n",
        "else:\n",
        "    print(\"‚ùå No JSON file found in dataset folder!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "8d3c2e46ba7d469f928a90b021bea362",
            "2b86fc569f24481380e22fb1115f813f",
            "4c95e7e4966a4993b75fa54999360fe0",
            "aa8e6c0f2a1b460f97b59d9c00224225",
            "5f4d75c4e68d4f118c79ba9212cb721c",
            "4078a476fea8441cbb7e83a616f0e682",
            "163d432d6509491b8c7831545e44d335",
            "ac20163d7a5640ff848567f3a9028984",
            "4dae440e57b54916b92a66b6f1a08723",
            "9f51cad56e874ac8923c449afcb4ca15",
            "f9b9e07f6c5d41c3a30266fdbf36b63c"
          ]
        },
        "id": "Fbx4HHRktYU0",
        "outputId": "b2ca47d1-4187-4104-ab05-1ecc663d2cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Using JSON: dataset/prescription_labeling.json\n",
            "üñºÔ∏è  Images from: dataset/images/Merge 300\n",
            "\n",
            "üìÇ Loading annotations...\n",
            "‚úÖ Loaded 302 tasks\n",
            "\n",
            "üé® Using 5 augmentation configs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n",
            "  self._set_keys()\n",
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-1953513360.py:28: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
            "  A.ShiftScaleRotate(\n",
            "/tmp/ipython-input-1953513360.py:45: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(15, 40), p=0.7),\n",
            "/tmp/ipython-input-1953513360.py:46: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, quality_upper=95, p=0.7),\n",
            "/tmp/ipython-input-1953513360.py:55: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  A.GaussNoise(var_limit=(10, 25), p=1.0),\n",
            "/tmp/ipython-input-1953513360.py:57: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=80, quality_upper=100, p=0.4),\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing:   0%|          | 0/302 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d3c2e46ba7d469f928a90b021bea362"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üìä AUGMENTATION COMPLETE\n",
            "======================================================================\n",
            "Original tasks:       302\n",
            "Augmented tasks:      1510\n",
            "Failed:               0\n",
            "Skipped (no boxes):   0\n",
            "Total dataset:        1812\n",
            "Augmentation factor:  5.0x\n",
            "======================================================================\n",
            "‚úÖ JSON: augmented_output/augmented_annotations.json\n",
            "‚úÖ Images: augmented_output/augmented_images/\n",
            "\n",
            "üéâ ALL DONE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create ZIP of augmented dataset\n",
        "print(\"üì¶ Creating ZIP file...\")\n",
        "shutil.make_archive('augmented_dataset', 'zip', 'augmented_output')\n",
        "\n",
        "print(\"‚úÖ ZIP created: augmented_dataset.zip\")\n",
        "print(f\"üìä Size: {os.path.getsize('augmented_dataset.zip') / (1024*1024):.2f} MB\")\n",
        "\n",
        "# Download\n",
        "print(\"\\n‚¨áÔ∏è  Downloading...\")\n",
        "files.download('augmented_dataset.zip')\n",
        "print(\"‚úÖ Download started!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "kmtLGg5ItcrS",
        "outputId": "db1065b4-ce37-4486-e203-e84c0ff371d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Creating ZIP file...\n",
            "‚úÖ ZIP created: augmented_dataset.zip\n",
            "üìä Size: 369.44 MB\n",
            "\n",
            "‚¨áÔ∏è  Downloading...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c46237f8-ecbf-4b5a-94e7-9e3b04e46375\", \"augmented_dataset.zip\", 387388113)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download started!\n"
          ]
        }
      ]
    }
  ]
}